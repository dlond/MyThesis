%!TEX root = ../Thesis.tex
% Chapter 6

\chapter{Example 1-Cohomology Calculations}
\label{Chapter6}
\lhead{Chapter 6. \emph{Example 1-Cohomology Calculations}}
In this Chapter we calculate some examples of 1-cohomology.

We calculate the 1-cohomology of $B_2$, aided by the results in the previous Chapter. We also investigate the counterexamples to Propositions \ref{ufixes} and \ref{uabelian} as pointed out in the respective Remarks \ref{g2counter} and \ref{c3counter} of the previous Chapter.

In our last example calculation we use the 1-cohomology to find a family of maps from $SL_2(k)$ to $B_4$ which gives infinitely many conjugacy classes. TODO result \ldots

\section{General Method}
The general method we use of calculating the 1-cohomology is outlined below.

For each $\alpha \in \Delta$ (the simple roots)
	\begin{itemize}
	\item[1.] Fix $x\in H^1(SL_2(k), V_\alpha)_{\rho_r}$. Then there exists $\sigma\in Z^1(SL_2(k), V_\alpha)_{\rho_r}$ such that $\psi(\sigma) = x$ and $\sigma\left(y\right) = 1 \in V_\alpha$ for all $y\in T_2(k)$ (Lemma \ref{trivial_on_t}).
	\item[2.] Use Lemma \ref{lem:second} to determine $\sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right)$. 
	\item[3.] If $\sigma\left(y\right) = 1$ for all $y\in B_2(k)$ then $H^1(SL_2(k), V_\alpha)_{\rho_r}$ is trivial by Lemma \ref{sl2_b_inj}.
	\item[4.] Otherwise, determine $\sigma\left(\begin{matrix}a & b\\c & d\end{matrix}\right)$ for $c \neq 0$ by
	\begin{align*}
	\sigma\left(\begin{matrix}a & b\\c & d\end{matrix}\right) &= \sigma\left(
			\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)
			\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
			\left(\begin{matrix}-c & -d\\0 & -c^{-1}\end{matrix}\right)
			\right),
	\end{align*}
	and show that $\sigma$ is a well-defined 1-cocycle on $SL_2(k)$.
	\item[5.] Calculate $H^1(SL_2(k), V_\alpha)_{\rho_r}$.
	\item[6.] Calculate $H^1(SL_2(k), V_\alpha)_{\rho_r}/C_L(\rho_r)$ and use Theorem \ref{main_thm} to get information about conjugacy classes in $\mathrm{Hom}(SL_2(k), P_\alpha)$.
	\end{itemize}
We elaborate on step 4. Given $\sigma\left(\begin{matrix}a & b \\ 0 & a^{-1}\end{matrix}\right)$ and $\sigma\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)$, the obvious way to piece together a 1-cocycle on $SL_2(k)$ is, for $c\neq 0$
\begin{align}\label{fullsigma}
	\sigma\left(\begin{matrix}a & b\\c & d\end{matrix}\right)
	&=
	\sigma\left(
		\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left(\begin{matrix}-c & -d\\0 & -c^{-1}\end{matrix}\right)
	\right) \nonumber \\
	&=
	\sigma\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\left[
		\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\cdot
	\sigma\left(
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left(\begin{matrix}-c & -d\\0 & -c^{-1}\end{matrix}\right)
	\right)
	\right]\nonumber \\
	&=
	\sigma\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\left[
		\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\cdot
	\left(\sigma
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left[
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix}-c & -d\\0 & -c^{-1}\end{matrix}\right)
		\right]
	\right)
	\right]\nonumber \\
	&=
	\sigma\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\left[
		\left(\begin{matrix}1 & ac^{-1}\\0 & 1\end{matrix}\right)\cdot
	\left(\sigma
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left[
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix}c & d\\0 & c^{-1}\end{matrix}\right)
		\right]
	\right)
	\right],
\end{align}
where we apply Corollary \ref{sigmaneg} at the last step.

TODO Ben's paper.
Then to check that $\sigma$ is a well-defined 1-cocycle on $SL_2(k)$ amounts to checking that $\sigma$ satisfies the following conditions, based on Steinberg's presentation for $SL_2$ \cite{}.
\begin{align}
	&\sigma(x_\alpha(t_1))\left[x_\alpha(t_1)\cdot \sigma(x_\alpha(t_2)))\right] = \sigma(x_\alpha(t_1+t_2)) \\
	&\sigma(h_\alpha(t_1))\left[h_\alpha(t_1) \cdot \sigma(h_\alpha(t_2)))\right] = \sigma(h_\alpha(t_1t_2)) \\
	&\sigma(n_\alpha(t))\left[n_\alpha(t) \cdot \sigma(x_\alpha(u)) \left[x_\alpha(u) \cdot \sigma(n_\alpha(t)^{-1})\right]\right] = \sigma(x_{-\alpha}(-t^{-2}u)).
\end{align}

We will need to determine the action of $SL_2(k)$ on $V_\alpha$ and the group law on $V_\alpha$ which often involves lengthy computations using the commutator relations. For clarity, we will use column vector notation.
\begin{align*}
\left(\begin{matrix}
	v_{1}\\ v_{2}\\ \vdots\\ v_{n}
\end{matrix}\right) = \epsilon_{\delta_1}(v_1)\epsilon_{\delta_2}(v_2)\cdots\epsilon_{\delta_n}(v_n) \in V_\alpha
\end{align*}

Determining the values of $\sigma$ are straightforward. Lemma \ref{lem:second} gives $\sigma\left(\begin{matrix}a & b \\ 0 & a^{-1}\end{matrix}\right)$ up to some constants $\mu_\delta\in k$, while $\sigma\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)$ is computed as follows.
\begin{proposition} \label{prop:A}
Let $\sigma$ satisfy the hypotheses of Lemma \ref{lem:second}. Then there exist constants $\lambda_\delta\in k$ such that
\begin{align}
	\sigma\left(\begin{matrix}0 & 1 \\ -1 & 0\end{matrix}\right) &=
	\sigma
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
	\left[
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)\cdot
		\left(
		\sigma
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)
		\left[
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)\right]
		\right)
	\right] \label{prop:A:eqn1}\\
	&= \prod_{\delta\in\mathcal{D}} \epsilon_\delta(\lambda_\delta),\label{prop:A:eqn2}
\end{align}
where $\mathcal{D} = \{\delta\in \Phi^+-\{\alpha\}\,|\,\langle\delta,\alpha\rangle = 0\}$.
\end{proposition}
\begin{proof}
Since
\begin{align*}
		\left(\begin{matrix}t & 0\\0 & t^{-1}\end{matrix}\right)
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right) =
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left(\begin{matrix}t^{-1} & 0\\0 & t\end{matrix}\right),
\end{align*}
we have
\begin{align*}
	\sigma\left(
		\left(\begin{matrix}t & 0\\0 & t^{-1}\end{matrix}\right)
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
	\right) &= 
	\sigma\left(
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
		\left(\begin{matrix}t^{-1} & 0\\0 & t\end{matrix}\right)
	\right) \\
	\Rightarrow
		\left(\begin{matrix}t & 0\\0 & t^{-1}\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right)
	 &= 
	\sigma
		\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right).
\end{align*}
Therefore $\sigma\left(\begin{matrix}0 & 1\\ -1 & 0\end{matrix}\right)$ is fixed under the action of $T_2(k)$ and so is of the form
\begin{align*}
\sigma\left(\begin{matrix}0 & 1\\-1 & 0\end{matrix}\right) = \prod_{\delta\in\mathcal{D}} \epsilon_\delta(\lambda_\delta),
\end{align*}
for some $\lambda_\delta\in k$, where
\begin{align*}
	\mathcal{D} = \{\delta\in \Phi^+-\{\alpha\}\,|\,\langle\delta,\alpha\rangle = 0\}.
\end{align*}
Furthermore, since
\begin{align*}
\left(\begin{matrix} 0 & 1\\ -1 & 0\end{matrix}\right)
&=
\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)
\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right),
\end{align*}
we have
\begin{align*}
	\sigma
		\left(\begin{matrix} 0 & 1\\ -1 & 0\end{matrix}\right)
	&=
	\sigma\left(
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
	\right) \\
	&=
	\sigma
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
	\left[
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)\cdot
		\sigma
		\left(
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
		\right)
	\right] \\
	&=
	\sigma
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)
	\left[
		\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)\cdot
		\left(
		\sigma
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)
		\left[
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix} 1 & -1\\ 0 & 1\end{matrix}\right)\right]
		\right)
	\right].
\end{align*}
\end{proof}


%	Throughout we use the notation of Humphreys \cite[Chapter XI]{humphreys1975linear}.

\section{$G = B_2$}
\label{b2}

Let $T$ be a maximal torus of $B_2$ over an algebraically closed field $k$ of characteristic $p$. We label the positive roots for $B_2$ as $\alpha, \beta, \alpha + \beta, 2\alpha + \beta$. We have from \cite[\S 33.4]{humphreys1975linear}:
\begin{align*}
\epsilon_\beta (y) \epsilon_\alpha (x) &= \epsilon_\alpha (x) \epsilon_\beta (y) \epsilon_{\alpha + \beta} (xy) \epsilon_{2\alpha+\beta} (x^2y) \\
\epsilon_{\alpha + \beta} (y) \epsilon_\alpha (x) &= \epsilon_\alpha (x) \epsilon_{\alpha + \beta} (y) \epsilon_{2\alpha + \beta} (2xy),
\end{align*}
and 
\begin{align*}
n_\alpha \epsilon_\beta(x) n_\alpha^{-1} &= \epsilon_{2\alpha+\beta}(x)\\
n_\alpha \epsilon_{\alpha+\beta}(x) n_\alpha^{-1} &= \epsilon_{\alpha+\beta}(-x)\\
n_\alpha \epsilon_{2\alpha+\beta}(x) n_\alpha^{-1} &= \epsilon_{\beta}(x)\\
n_\beta \epsilon_\alpha(x) n_\beta^{-1} &= \epsilon_{\alpha+\beta}(x)\\
n_\beta \epsilon_{\alpha+\beta}(x) n_\beta^{-1} &= \epsilon_{\alpha}(-x)\\
n_\beta \epsilon_{2\alpha+\beta}(x) n_\beta^{-1} &= \epsilon_{2\alpha+\beta}(x)
\end{align*}
A proper parabolic subgroup of $B_2$ is conjugate to one of
\begin{align*}
P_\alpha &= \langle B, U_{-\alpha} \rangle\\
P_\beta &= \langle B, U_{-\beta} \rangle,
\end{align*}
where $B$ is the Borel subgroup of $B_2$ containing $T$
\begin{align*}
B=\langle T, U_\alpha, U_\beta, U_{\alpha + \beta}, U_{2\alpha+\beta}\rangle.
\end{align*}
The two parabolic subgroups have the Levi decompositions
\begin{align*}
P_\alpha &= R_u(P_\alpha) \rtimes L_\alpha \\
&= \langle U_\beta, U_{\alpha + \beta}, U_{2\alpha + \beta} \rangle \rtimes \langle T, U_\alpha, U_{-\alpha} \rangle \\ 
P_\beta &= R_u(P_\beta) \rtimes L_\beta \\
&= \langle U_\alpha, U_{\alpha+\beta}, U_{2\alpha + \beta} \rangle \rtimes \langle T, U_\beta, U_{-\beta} \rangle \\
\end{align*}

\subsection{$V = R_u(P_\alpha)$}
\label{b2:alpha}

Let $V_\alpha=R_u(P_\alpha)=\langle U_\beta, U_{\alpha + \beta}, U_{2\alpha + \beta} \rangle$. Note that $V_\alpha$ is abelian.
We will write $\mathbf{v}\in V_\alpha$ as a column vector for convenience,
\begin{align*}
	\left(\begin{matrix}v_1\\v_2\\v_3\end{matrix}\right) = \epsilon_\beta(v_1)\epsilon_{\alpha+\beta}(v_2)\epsilon_{2\alpha+\beta}(v_3),
\end{align*}
and we compute the following.
\begin{align*}
\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right) \cdot \mathbf{v} 
&= 
\rho_r\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right) \mathbf{v}\left( \rho_r\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right)\right)^{-1} \\
&=
\epsilon_ \alpha (u^{p^r}) \epsilon_ \beta (v_1)\epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3) \epsilon_ \alpha (-u^{p^r}) \\
&=
\epsilon_ \alpha (u^{p^r}) \epsilon_ \beta (v_1) \epsilon_{\alpha+\beta}(v_2) \epsilon_ \alpha (-u^{p^r}) \epsilon_{2\alpha+\beta}(v_3) \\
&=
\epsilon_ \alpha (u^{p^r}) \epsilon_ \beta (v_1)  \epsilon_ \alpha (-u^{p^r}) \epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(-2u^{p^r}v_2)\epsilon_{2\alpha+\beta}(v_3)\\
&=
\epsilon_ \alpha (u^{p^r}) \epsilon_ \alpha (-u^{p^r})  \epsilon_ \beta (v_1) \epsilon_{\alpha+\beta}(-u^{p^r}v_1) \epsilon_{2\alpha+\beta}(u^{2p^r}v_1) \epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3-2u^{p^r}v_2)\\
&=
\epsilon_ \beta (v_1)  \epsilon_{\alpha+\beta}(v_2-u^{p^r}v_1) \epsilon_{2\alpha+\beta}(v_3-2u^{p^r}v_2 + u^{2p^r}v_1)\\
&= \left(\begin{matrix} v_1 \\ v_2-u^{p^r}v_1 \\ v_3-2u^{p^r}v_2 + u^{2p^r}v_1 \end{matrix}\right),
\end{align*}
\begin{align*}
\left(\begin{matrix} t & 0 \\ 0 & t^{-1}\end{matrix}\right) \cdot \mathbf{v}
&=
\rho_r\left(\begin{matrix}t & 0 \\ 0 & t^{-1}\end{matrix}\right) \mathbf{v} \left(\rho_r\left(\begin{matrix}t & 0 \\ 0 & t^{-1}\end{matrix}\right)\right)^{-1} \\
&=
\alpha^\vee(t^{p^r})\epsilon_\beta(v_1)\epsilon_{\alpha+\beta}(v_2)\epsilon_{2\alpha+\beta}(v_3)\left(\alpha^\vee(t^{p^r})\right)^{-1} \\
&=
\epsilon_\beta\left(\beta(\alpha^\vee(t^{p^r}))v_1\right)\epsilon_{\alpha+\beta}\left((\alpha+\beta)(\alpha^\vee(t^{p^r}))v_2\right)\epsilon_{2\alpha+\beta}\left((2\alpha+\beta)(\alpha^\vee(t^{p^r}))v_3\right) \\
&=
\epsilon_\beta\left(t^{\langle\beta,\alpha\rangle p^r}v_1\right)\epsilon_{\alpha+\beta}\left(t^{\langle\alpha+\beta,\alpha\rangle p^r}v_2\right)\epsilon_{2\alpha+\beta}\left(t^{\langle2\alpha+\beta,\alpha\rangle p^r}v_3\right) \\
&=
\left(\begin{matrix} t^{-2p^r}v_1 \\ v_2 \\ t^{2p^r}v_3 \end{matrix}\right) \\
\left(\begin{matrix} 0 & 1 \\ -1 & 0 \end{matrix}\right) \cdot \mathbf{v} 
&=
\rho_r\left(\begin{matrix} 0 & 1 \\ -1 & 0\end{matrix}\right) \mathbf{v}\left( \rho_r\left(\begin{matrix} 0 & 1 \\ -1 & 0\end{matrix}\right)\right)^{-1} \\
&= 
n_ \alpha  \epsilon_ \beta (v_1)\epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3) n_ \alpha^{-1}\\
&= 
n_ \alpha  \epsilon_\beta (v_1) n_ \alpha^{-1}n_ \alpha \epsilon_{\alpha+\beta}(v_2) n_ \alpha^{-1} n_ \alpha \epsilon_{2\alpha+\beta}(v_3) n_ \alpha^{-1}\\
&= 
\epsilon_{2\alpha+\beta} (v_1) \epsilon_{\alpha+\beta}(-v_2)  \epsilon_{\beta}(v_3) \\
&= 
\epsilon_{\beta}(v_3) \epsilon_{\alpha+\beta}(-v_2) \epsilon_{2\alpha+\beta} (v_1)\\
&= \left(\begin{matrix} v_3 \\ -v_2 \\ v_1 \end{matrix}\right).
\end{align*}
This is enough to determine the action of $SL_2(k)$ on $V_\alpha$. We leave the details to the reader.
\begin{align*}
\left(\begin{matrix}a & b \\ c & d\end{matrix}\right) \cdot \mathbf{v} 
&= \left(\begin{matrix}
	d^{2p^r}v_1 - 2(cd)^{p^r}v_2 + c^{2p^r}v_3 \\
	(ad + bc)^{p^r}v_2 - (bd)^{p^r}v_1 - (ac)^{p^r}v_3 \\
	b^{2p^r}v_1 - 2(ab)^{p^r}v_2 + a^{2p^r}v_3
\end{matrix}\right)
\end{align*}

Let $x\in H^1(SL_2(k), V_\alpha)_{\rho_r}$. By Proposition \ref{trivial_on_t} there exists $\sigma\in Z^1(SL_2(k), V_\alpha)_{\rho_r}$ such that $\sigma(y) = 1$ for all $y\in T_2(k)$ and $\psi(\sigma) = x$. By Lemma \ref{lem:first}, we can apply Lemma \ref{lem:second}, which gives
\begin{align*}
	\sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) &= \epsilon_{2\alpha+\beta}\left(\mu_3(ab)^{p^r}\right),
\end{align*}
for all $a\in k^*, b\in k$, for some fixed $\mu_3\in k$.

Suppose $p\neq 2$, and let $\mathbf{w} = \left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)\in V_\alpha$. Now consider $\chi^{SL_2(k)}_\mathbf{w} \in B^1(SL_2(k), V_\alpha)_{\rho_r}$.

\begin{align*}
	\chi^{SL_2(k)}_\mathbf{w}\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) &= \mathbf{w} - \left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) \cdot \mathbf{w} \\
	%&=
	%\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	%-\left(
	%\left(\begin{matrix}a & 0\\0 & a^{-1}\end{matrix}\right)
	%\left(\begin{matrix}1 & a^{-1}b\\0 & 1\end{matrix}\right)\cdot
	%\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	%\right)\\
	&=
	\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	-
	\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right)\cdot
	\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right) \\
	%&=
	%\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	%-
	%\left(\begin{matrix}a & 0\\0 & a^{-1}\end{matrix}\right)\cdot
	%\left(\begin{matrix}0\\2^{-1}\mu_3\\-(a^{-1}b)^{p^r}\mu_3\end{matrix}\right) \\
	&=
	\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	-
	\left(\begin{matrix}0\\2^{-1}\mu_3\\-2(ab)^{p^r} (2^{-1}\mu_3)\end{matrix}\right) \\
	&=\left(\begin{matrix}0\\2^{-1}\mu_3\\0\end{matrix}\right)
	-\left(\begin{matrix}0\\2^{-1}\mu_3\\-(ab)^{p^r}\mu_3\end{matrix}\right) \\
	&=\left(\begin{matrix}0\\0\\(ab)^{p^r}\mu_3\end{matrix}\right) \\
	&= \sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right).
\end{align*}
This shows that if $p\neq 2$ then $H^1(B_2(k), V_\alpha)_{\rho_r}$ is trivial, and hence $H^1(SL_2(k), V_\alpha)_{\rho_r}$ is trivial by Lemma \ref{sl2_b_inj}.

We proceed with $p=2$.
By Lemma \ref{lem:second} and Remark \ref{rem:second} there exist constants $\mu_1,\mu_3\in k$ such that
	\begin{align*}
	\sigma
			\left(\begin{matrix}a & b \\ 0 & a^{-1}\end{matrix}\right)
	&=
	\left(\begin{matrix}0 \\ 0 \\ \mu_3(ab)^{2^r}\end{matrix}\right),
	\end{align*}
and 
\begin{align*}
	\sigma\left(\begin{matrix}d^{-1} & 0 \\ c & d\end{matrix}\right)
	&=
	\left(\begin{matrix}\mu_1(cd)^{2^r}\\0\\0\end{matrix}\right).
	\end{align*}
	
Furthermore, by Equation \ref{prop:A:eqn2} there exists $\lambda_2\in k$ such that
\begin{align*}
	\sigma\left(\begin{matrix}0 & 1\\1 & 0\end{matrix}\right) = \left(\begin{matrix}0 \\ \lambda_2 \\ 0 \end{matrix}\right),
\end{align*}
and by Equation \ref{prop:A:eqn1}
\begin{align*}
\sigma\left(\begin{matrix}0 & 1 \\ 1 & 0\end{matrix}\right)
&=
	\sigma
		\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right) +
		\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right)\cdot
		\left(
		\sigma
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right) +
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)\cdot
		\sigma\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right)
		\right)
	\\
&=
		\left(\begin{matrix} 0 \\ 0 \\ \mu_3 \end{matrix}\right) +
		\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right)\cdot
		\left(
		\left(\begin{matrix} \mu_1 \\ 0 \\ 0\end{matrix}\right) +
		\left(\begin{matrix} 1 & 0\\ 1 & 1\end{matrix}\right)\cdot
		\left(\begin{matrix} 0 \\ 0 \\ \mu_3\end{matrix}\right)
		\right)
	\\
&=
		\left(\begin{matrix} 0 \\ 0 \\ \mu_3 \end{matrix}\right) +
		\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right)\cdot
		\left(
		\left(\begin{matrix} \mu_1 \\ 0 \\ 0\end{matrix}\right) +
		\left(\begin{matrix} \mu_3 \\ \mu_3 \\ \mu_3\end{matrix}\right)
		\right)
	\\
&=
		\left(\begin{matrix} 0 \\ 0 \\ \mu_3 \end{matrix}\right) +
		\left(\begin{matrix} 1 & 1\\ 0 & 1\end{matrix}\right)\cdot
		\left(\begin{matrix} \mu_1 + \mu_3 \\ \mu_3 \\ \mu_3\end{matrix}\right)
	\\
&=
		\left(\begin{matrix} 0 \\ 0 \\ \mu_3 \end{matrix}\right) +
		\left(\begin{matrix} \mu_1 + \mu_3 \\ \mu_3 + \mu_1 + \mu_3 \\ \mu_1 + \mu_3 + \mu_3\end{matrix}\right)
	\\
&=
		\left(\begin{matrix} \mu_1 + \mu_3 \\ \mu_1 \\ \mu_1 + \mu_3\end{matrix}\right).
\end{align*}
Therefore $\lambda_2 = \mu_1 = \mu_3$. Writing $\mu = \mu_1 (= \mu_3)$, we have
\begin{align*}
\sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) = \left(\begin{matrix}0 \\ 0 \\ (ab)^{2^r}\mu\end{matrix}\right),\quad
\sigma\left(\begin{matrix}d^{-1} & 0\\c & d\end{matrix}\right) = \left(\begin{matrix}(cd)^{2^r}\mu \\ 0 \\ 0\end{matrix}\right),\quad
\sigma\left(\begin{matrix}0 & 1\\1 & 0\end{matrix}\right) = \left(\begin{matrix}0 \\ \mu \\ 0\end{matrix}\right).
\end{align*}

	Suppose $c\neq 0$. Then
	\begin{align}
	\sigma
			\left(\begin{matrix}a & b \\ c & d\end{matrix}\right)
			 &=
	\sigma\left(
			\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
			\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
			\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
			\right) \nonumber \\
		&=
	\sigma
			\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
			 + 
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)\cdot
	\left(
			\sigma
				\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
				 +
			\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)\cdot
			\sigma
				\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
			\right)\nonumber \\
		&=
			\left(\begin{matrix} 0 \\ 0 \\ (ac^{-1})^{2^r}\mu\end{matrix}\right)
			 + 
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)\cdot
	\left(
				\left(\begin{matrix} 0 \\ \mu \\ 0 \end{matrix}\right)
				 +
			\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)\cdot
				\left(\begin{matrix} 0 \\ 0 \\ (cd)^{2^r}\mu \end{matrix}\right)
			\right)\nonumber \\
		&=
			\left(\begin{matrix} 0 \\ 0 \\ (ac^{-1})^{2^r}\mu\end{matrix}\right)
			 + 
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)\cdot
	\left(
				\left(\begin{matrix} 0 \\ \mu \\ 0 \end{matrix}\right)
				 +
				\left(\begin{matrix} (cd)^{2^r}\mu \\ 0 \\ 0 \end{matrix}\right)
			\right)\nonumber \\
		&=
			\left(\begin{matrix} 0 \\ 0 \\ (ac^{-1})^{2^r}\mu\end{matrix}\right)
			 + 
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)\cdot
				\left(\begin{matrix} (cd)^{2^r}\mu \\ \mu \\ 0 \end{matrix}\right)
 \nonumber \\
		&=
			\left(\begin{matrix} 0 \\ 0 \\ (ac^{-1})^{2^r}\mu\end{matrix}\right)
			 + 
			\left(\begin{matrix} (cd)^{2^r}\mu \\ \mu + (ac^{-1})^{2^r}(cd)^{2^r}\mu\\ (ac^{-1})^{2^{r+1}}(cd)^{2^r}\mu \end{matrix}\right)
 \nonumber \\
		&=
			\left(\begin{matrix} (cd)^{2^r}\mu \\ \mu + (ac^{-1})^{2^r}(cd)^{2^r}\mu\\(ac^{-1})^{2^r}\mu + (ac^{-1})^{2^{r+1}}(cd)^{2^r}\mu \end{matrix}\right)
 \nonumber \\
		&=
			\left(\begin{matrix} (cd)^{2^r}\mu \\ (1 + ad)^{2^r}\mu \\ (1+ad)^{2^r}(ac^{-1})^{2^r}\mu \end{matrix}\right)
 \nonumber \\
		&=
			\left(\begin{matrix} (cd)^{2^r}\mu \\ (bc)^{2^r}\mu \\ (ab)^{2^r}\mu \end{matrix}\right)\label{eqn:b2a}.
	\end{align}
Note that substituting $c=0$ gives
\begin{align*}
\sigma\left(\begin{matrix}a & b \\ 0 & a^{-1}\end{matrix}\right) = \left(\begin{matrix} 0 \\ 0 \\ (ab)^{2^r}\mu\end{matrix}\right),
\end{align*}
substituting $b=0$ gives
\begin{align*}
\sigma\left(\begin{matrix}d^{-1} & 0 \\ c & d\end{matrix}\right) = \left(\begin{matrix} (cd)^{2^r}\mu \\ 0 \\ 0\end{matrix}\right),
\end{align*}
and substituting $a = d = 0, b = c = 1$ gives
\begin{align*}
\sigma\left(\begin{matrix}0 & 1 \\ 1 & 0\end{matrix}\right) = \left(\begin{matrix} 0 \\ \mu \\ 0\end{matrix}\right),
\end{align*}
so we take Equation \ref{eqn:b2a} to be the general form of a 1-cocycle $\sigma:SL_2(k)\rightarrow V_\alpha$ such that $\sigma(y) = 1$ for all $y\in T_2(k)$.

We now show that $\sigma$ as defined in Equation \ref{eqn:b2a} satisfies the 1-cocycle condition. TODO Steinberg or otherwise.

We calculate the 1-cohomology by finding $\tau\in Z^1(SL_2(k), V_\alpha)_{\rho_r}$ such that $\tau = \sigma + \chi^{SL_2(k)}_\mathbf{v}$, for some $\mathbf{v}\in V_\alpha$. We may assume $\tau(y) = 1$ for all $y \in T_2(k)$, hence $\mathbf{v}$ is fixed by the action of $T_2(k)$. 

To this end, let $\mathbf{v} = \left(\begin{matrix}0\\v\\0\end{matrix}\right)$. Since
	$\left(\begin{matrix}a & b\\c & d\end{matrix}\right) \cdot \left(\begin{matrix}0\\v\\0\end{matrix}\right) =
	\left(\begin{matrix}0\\v\\0\end{matrix}\right),
\chi^{SL_2(k)}_v$ is trivial.
This shows that for each $\mu\in k$, $\psi(\sigma_\mu)$ is a distinct element in the 1-cohomology, where
\begin{align*}
	\sigma_\mu\left(\begin{matrix}a & b\\c & d\end{matrix}\right) = \left(\begin{matrix}(cd)^{2^r}\mu\\(bc)^{2^r}\mu\\(ad)^{2^r}\mu\end{matrix}\right).
\end{align*}

We now consider the action of $Z(L_\alpha)^\circ$, the connected centre of the Levi subgroup $L_\alpha$. We have $Z(L_\alpha)^\circ = \langle \gamma^\vee(x)\,|\,x \in k \rangle$ where $\gamma$ is a root in $\Phi$ such that $\langle \alpha, \gamma \rangle = 0$.

Since $\langle \alpha, \alpha + \beta\rangle = 0$, we may choose $\gamma = \alpha + \beta$.
Therefore $Z(L_ \alpha)^\circ = \langle (\alpha + \beta)^\vee(x)\,|\,x \in k \rangle$. Taking an element $\mathbf{s} = (\alpha + \beta)^\vee(s)$ of $Z(L_\alpha)^\circ$ we compute the action of $\mathbf{s}$ on the 1-cocycle $\sigma_\mu$ as follows.
\begin{align*}
\left(\mathbf{s}\cdot \sigma_\mu\right)
\left(\begin{matrix} a & b \\ c & d\end{matrix} \right) 
&=
(\alpha + \beta)^\vee(s) \epsilon_\beta \left(\mu (cd)^{2^r} \right)\epsilon_{\alpha+\beta} \left(\mu(bc)^{2^r} \right)\epsilon_{2\alpha + \beta} \left(\mu(ab)^{2^r} \right)(\alpha + \beta)^\vee(s)^{-1}\\
&=  \epsilon_\beta\left(s^{\langle\beta , \alpha+\beta\rangle}\mu (cd)^{2^r} \right)\epsilon_{\alpha+\beta} \left(s^{\langle \alpha+\beta, \alpha+\beta \rangle} \mu(bc)^{2^r} \right)\epsilon_{2\alpha + \beta} \left(s^{\langle 2\alpha+\beta, \alpha+\beta\rangle}\mu(ab)^{2^r}\right) \\
&=
\left(\begin{matrix}
(s^2\mu)(cd)^{2^r} \\
(s^2\mu)(bc)^{2^r} \\
(s^2\mu)(ab)^{2^r}
\end{matrix}\right).
\end{align*}

So we see that the infinitely many equivalence classes of 1-cocycles collapse to just two classes when we consider the action of $Z(L_\alpha)^\circ$, represented by the 1-cocycles $\sigma_0$ and $\sigma_1$.

\subsection{$V = R_u(P_\beta)$}
\label{b2:beta}

Let $V_\beta = R_u(P_\beta) = \langle U_\alpha, U_{\alpha + \beta}, U_{2\alpha + \beta} \rangle$.

Note that $V$ is not abelian in general. The Group Law for $V$ can be computed as follows. Writing $\mathbf{v}\in V_\beta$ as
\begin{align*}
	\left(\begin{matrix} v_1\\v_2\\v_3\end{matrix}\right) = \epsilon_\alpha(v_1)\epsilon_{\alpha+\beta}(v_2)\epsilon_{2\alpha+\beta}(v_3),
\end{align*}
for $\mathbf{v}, \mathbf{w}\in V_\beta$ we have
\begin{align*}
\mathbf{v}\mathbf{w}
&= 
\epsilon_\alpha(v_1)\epsilon_{\alpha+\beta}(v_2)\epsilon_{2\alpha+\beta}(v_3) \epsilon_\alpha(w_1)\epsilon_{\alpha+\beta}(w_2)\epsilon_{2\alpha+\beta}(w_3)\\
&= 
\epsilon_\alpha(v_1)\epsilon_{\alpha+\beta}(v_2) \epsilon_\alpha(w_1)\epsilon_{\alpha+\beta}(w_2)\epsilon_{2\alpha+\beta}(v_3)\epsilon_{2\alpha+\beta}(w_3)\\
&= 
\epsilon_\alpha(v_1) \epsilon_\alpha(w_1) \epsilon_{\alpha + \beta}(v_2)\epsilon_{2\alpha+\beta}(2v_2w_1)\epsilon_{\alpha+\beta}(w_2)\epsilon_{2\alpha+\beta}(v_3)\epsilon_{2\alpha+\beta}(w_3)\\
&= 
\epsilon_\alpha(v_1 + w_1) \epsilon_{\alpha + \beta}(v_2 + w_2)\epsilon_{2\alpha+\beta}(v_3 + w_3 + 2v_2w_1)\\
&=
\left(\begin{matrix}
v_1 + w_1 \\
v_2 + w_2 \\
v_3 + w_3 + 2v_2w_1
\end{matrix}\right).
\end{align*}

We compute the following.
\begin{align*}
\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right) \cdot \mathbf{v} &= \rho_r\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right) \mathbf{v}\left( \rho_r\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right)\right)^{-1} \\
&=\epsilon_\beta (u^{p^r}) \epsilon_\alpha (v_1)\epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3) \epsilon_\beta (-u^{p^r}) \\
&=\epsilon_\alpha (v_1) \epsilon_\beta (u^{p^r}) \epsilon_{\alpha+\beta}(u^{p^r}v_1) \epsilon_{2\alpha+\beta}(u^{p^r}v_1^2) \epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3) \epsilon_\beta (-u^{p^r})  \\
&=\epsilon_\alpha (v_1) \epsilon_\beta (u^{p^r}) \epsilon_{\alpha+\beta}(v_2 + u^{p^r}v_1) \epsilon_{2\alpha+\beta}(v_3 + u^{p^r}v_1^2)  \epsilon_\beta (-u^{p^r})  \\
&=\epsilon_\alpha (v_1) \epsilon_{\alpha+\beta}(u^{p^r}v_1) \epsilon_{2\alpha+\beta}(u^{p^r}v_1^2) \epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3)\epsilon_\beta (u^{p^r})  \epsilon_\beta (-u^{p^r})  \\
&=\epsilon_\alpha (v_1)  \epsilon_{\alpha+\beta}(v_2 + u^{p^r}v_1) \epsilon_{2\alpha+\beta}(v_3 + u^{p^r}v_1^2) \\
&= \left(\begin{matrix} v_1 \\ v_2 + u^{p^r}v_1\\ v_3 + u^{p^r}v_1^2 \end{matrix}\right)\\
\left(\begin{matrix} t & 0 \\ 0 & t^{-1}\end{matrix}\right) \cdot \mathbf{v} &=
\rho_r\left(\begin{matrix} t & 0 \\ 0 & t^{-1}\end{matrix}\right) \mathbf{v}\left( \rho_r\left(\begin{matrix} t & 0 \\ 0 & t^{-1}\end{matrix}\right)\right)^{-1} \\
&= \beta^\vee(t^{p^r}) \epsilon_\alpha (v_1)
\epsilon_{\alpha+\beta}(v_2)
\epsilon_{2\alpha+\beta}(v_3) (\beta^\vee(t^{p^r}))^{-1} \\
&= \epsilon_\alpha \left(\alpha(\beta^\vee(t^{p^r}))v_1\right)
\epsilon_{\alpha+\beta} \left((\alpha+\beta)(\beta^\vee(t^{p^r}))v_2 \right)
\epsilon_{2\alpha+\beta} \left((2\alpha+\beta)(\beta^\vee(t^{p^r}))v_3 \right)\\
&= \epsilon_\alpha \left((t^{p^r})^{\langle \alpha, \beta \rangle}v_1 \right)
\epsilon_{\alpha+\beta} \left((t^{p^r})^{\langle \alpha+\beta, \beta \rangle}v_2 \right)
\epsilon_{2\alpha+\beta} \left((t^{p^r})^{\langle 2\alpha+\beta, \beta \rangle}v_3 \right)\\
&= \left(\begin{matrix} t^{-p^r}v_1 \\ t^{p^r}v_2\\ v_3 \end{matrix}\right) \\
\left(\begin{matrix} 0 & 1 \\ -1 & 0 \end{matrix}\right) \cdot \mathbf{v} &=
\rho_r\left(\begin{matrix} 0 & 1 \\ -1 & 0\end{matrix}\right) \mathbf{v}\left( \rho_r\left(\begin{matrix} 0 & 1 \\ -1 & 0\end{matrix}\right)\right)^{-1} \\
&= n_\beta  \epsilon_\alpha (v_1)\epsilon_{\alpha+\beta}(v_2) \epsilon_{2\alpha+\beta}(v_3) n_\beta^{-1}\\
&= n_\beta  \epsilon_\alpha (v_1) n_\beta^{-1}n_\beta \epsilon_{\alpha+\beta}(v_2) n_\beta^{-1} n_\beta \epsilon_{2\alpha+\beta}(v_3) n_\beta^{-1}\\
&= \epsilon_{\alpha+\beta} (v_1) \epsilon_{\alpha}(-v_2)  \epsilon_{2\alpha+\beta}(v_3) \\
&=\epsilon_{\alpha}(-v_2)  \epsilon_{\alpha+\beta} (v_1)  \epsilon_{2\alpha+\beta}(v_3 - 2v_1v_2) \\
&= \left(\begin{matrix} -v_2 \\ v_1 \\ v_3 - 2v_1v_2 \end{matrix}\right).
\end{align*}

This is enough to determine the action of $SL_2(k)$ on $V_\beta$ (we omit the details).
\begin{align*}
\left(\begin{matrix}
a & b \\ c & d
\end{matrix} \right) \cdot \mathbf{v} &=
\left(\begin{matrix}
c^{p^r}v_2 + d^{p^r}v_1 \\
a^{p^r}v_2 + b^{p^r}v_1 \\
v_3 + (ac)^{p^r}v_2^2 + (bd)^{p^r}v_1^2 + 2(bc)^{p^r}v_1v_2
\end{matrix}\right).
\end{align*}

Let $x\in H^1(SL_2(k), V_\beta)_{\rho_r}$. Then by Proposition \ref{trivial_on_t} there exists $\sigma \in Z^1(SL_2(k), V_\beta)_{\rho_r}$ such that $\sigma(y) = 1$ for all  $y\in T_2(k)$ and $\phi(\sigma) = x$. By Lemma \ref{lem:first} we can apply Lemma \ref{lem:second} to yield
\begin{align*}
\sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) &= \epsilon_{\alpha+\beta}(\mu_2(ab)^{2^{r-1}}),\\
\sigma\left(\begin{matrix}d^{-1} & 0\\c & d\end{matrix}\right) &= \epsilon_{\alpha}(\mu_1(cd)^{2^{r-1}}) \quad\textrm{(Remark \ref{rem:second})},
\end{align*}
for some $\mu_1,\mu_2 \in k$ if $p = 2$, and $\sigma(B_2(k)) = 1$ if $p>2$. Hence by Lemma \ref{} $H^1(SL_2(k), V_\beta)_{\rho_r}$ is trivial if $p > 2$.

Proceeding with $p=2$ we see that $V_\beta$ is abelian so we revert to additive notation.

By Equation \ref{prop:A:eqn2} there exists $\lambda_3 \in k$ such that
\begin{align*}
\sigma\left(\begin{matrix}0 & 1\\1 & 0\end{matrix}\right) = \left(\begin{matrix}0\\0\\ \lambda_3\end{matrix}\right),
\end{align*}

and by Equation \ref{prop:A:eqn1}
\begin{align*}
\sigma\left(
	\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}
\right)
&=
\sigma
	\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
 +
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\sigma
		\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}
	\right) +
	\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)\cdot
	\sigma
		\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\right)\\ 
&=
\left(\begin{matrix} 0 \\ \mu_2 \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\left(\begin{matrix} \mu_1 \\ 0 \\ 0 \end{matrix}\right)
	+
	\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)\cdot
	\left(\begin{matrix} 0 \\ \mu_2 \\ 0 \end{matrix}\right)
\right)\\ 
&=
\left(\begin{matrix} 0 \\ \mu_2 \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\left(\begin{matrix} \mu_1 \\ 0 \\ 0 \end{matrix}\right)
	+
	\left(\begin{matrix} \mu_2 \\ \mu_2 \\ \mu_2^2 \end{matrix}\right)
\right)\\ 
&=
\left(\begin{matrix} 0 \\ \mu_2 \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right) \cdot
\left(\begin{matrix} \mu_1 + \mu_2 \\ \mu_2 \\ \mu_2^2 \end{matrix}\right)\\
&=
\left(\begin{matrix} 0 \\ \mu_2 \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} \mu_1 + \mu_2 \\ \mu_1 \\ \mu_1^2 \end{matrix}\right)\\
&=
\left(\begin{matrix} \mu_1 + \mu_2 \\ \mu_1 + \mu_2 \\ \mu_1^2 \end{matrix}\right).
\end{align*}

Therefore $\mu_1 = \mu_2$ and $\lambda_3 = \mu_1^2 (=\mu_2^2)$. Writing $\mu = \mu_1 (=\mu_2)$, we have
\begin{align*}
\sigma\left(\begin{matrix}a & b\\0 & a^{-1}\end{matrix}\right) = \left(\begin{matrix}0 \\ \mu(ab)^{2^{r-1}}\\ 0\end{matrix}\right), \quad
\sigma\left(\begin{matrix}d^{-1} & 0\\c & d\end{matrix}\right) = \left(\begin{matrix}\mu(cd)^{2^{r-1}}\\ 0\\0\end{matrix}\right), \quad
\sigma\left(\begin{matrix}0 & 1\\1 & 0\end{matrix}\right) = \left(\begin{matrix}0\\ 0\\ \mu^2\end{matrix}\right).
\end{align*}

Suppose $c\neq0$. Then
\begin{align}
\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) 
&=
\sigma
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
	\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
	\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
 \nonumber\\
&=
\sigma
	\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
 +
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\sigma
		\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
	 +
	\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) \cdot
	\sigma
		\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
\right)\nonumber \\
&=
\left(\begin{matrix} 0 \\ \mu(ac^{-1})^{2^{r-1}} \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\left(\begin{matrix} 0 \\ 0 \\ \mu^2 \end{matrix}\right)
	+
	\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) \cdot
	\left(\begin{matrix} 0 \\ \mu(cd)^{2^{r-1}} \\ 0 \end{matrix}\right)
\right) \nonumber\\
&=
\left(\begin{matrix} 0 \\ \mu(ac^{-1})^{2^{r-1}} \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\left(
	\left(\begin{matrix} 0 \\ 0 \\ \mu^2 \end{matrix}\right)
	+
	\left(\begin{matrix} \mu(cd)^{2^{r-1}} \\ 0 \\ 0 \end{matrix}\right)
\right) \nonumber\\
&=
\left(\begin{matrix} 0 \\ \mu(ac^{-1})^{2^{r-1}} \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\left(\begin{matrix} \mu(cd)^{2^{r-1}}\\ 0 \\ \mu^2 \end{matrix}\right) \nonumber\\
&=
\left(\begin{matrix} 0 \\ \mu(ac^{-1})^{2^{r-1}} \\ 0 \end{matrix}\right)
+
\left(\begin{matrix} \mu(cd)^{2^{r-1}} \\ (ac^{-1})^{2^r} \mu(cd)^{2^{r-1}}  \\ \mu^2 +  (ac^{-1})^{2^r} \left(\mu(cd)^{2^{r-1}}\right)^2  \end{matrix}\right)
 \nonumber\\
&=
\left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ac^{-1} + a^2c^{-1}d \right)^{2^{r-1}} \\ \mu^2\left( 1 + ad\right)^{2^r} \end{matrix}\right) \nonumber \\
&=
\left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ab \right)^{2^{r-1}} \\ \mu^2\left( bc \right)^{2^r} \end{matrix}\right). \label{eqn:b2b}
\end{align}

Note that substituting $c=0$ gives
\begin{align*}
\sigma\left(\begin{matrix}a & b \\ 0 & a^{-1}\end{matrix}\right) = \left(\begin{matrix}0 \\ \mu(ab)^{2^{r-1}}\\ 0\end{matrix}\right),
\end{align*}
substituting $b=0$ gives
\begin{align*}
\sigma\left(\begin{matrix}d^{-1} & 0 \\ c & d\end{matrix}\right) = \left(\begin{matrix}\mu(cd)^{2^{r-1}} \\ 0 \\0 \end{matrix}\right),
\end{align*}
and substituting $a = d = 0, b = c=1$ gives
\begin{align*}
\sigma\left(\begin{matrix}0 & 1 \\ 1 & 0\end{matrix}\right) = \left(\begin{matrix}0  \\ 0\\ \mu^2\end{matrix}\right),
\end{align*}
so we take Equation \ref{eqn:b2b} to be the general form of a 1-cocycle $\sigma:SL_2(k)\rightarrow V_\beta$ such that $\sigma(y) = 1$ for all  $y\in T_2(k)$. We now show that Equation \ref{eqn:b2b} is a well-defined. TODO

We calculate the 1-cohomology by calculating $\tau = \sigma + \chi^{SL_2(k)}_\mathbf{v}$ such that $\mathbf{v} \in V_\beta$ is fixed under the action of $T_2(k)$. To this end let $\mathbf{v} = \left(\begin{matrix}0 \\ 0 \\ v_3\end{matrix}\right)$.
\begin{align*}
\tau\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &=
\mathbf{v} + \sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) + 
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) \cdot \mathbf{v} \\
 &=
\left(\begin{matrix} 0 \\ 0 \\ v_3 \end{matrix}\right) + 
\left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ab \right)^{2^{r-1}} \\ \mu^2\left( bc \right)^{2^r} \end{matrix}\right)+ 
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) \cdot 
\left(\begin{matrix} 0 \\ 0 \\ v_3 \end{matrix}\right) \\
 &=
\left(\begin{matrix} 0 \\ 0 \\ v_3 \end{matrix}\right) + 
\left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ab \right)^{2^{r-1}} \\ \mu^2\left( bc \right)^{2^r} \end{matrix}\right)+ 
\left(\begin{matrix} 0 \\ 0 \\ v_3 \end{matrix}\right) \\
&= \left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ab \right)^{2^{r-1}} \\ \mu^2\left( bc \right)^{2^r} \end{matrix}\right).
\end{align*}
Therefore, for each $\mu$ in $k$ we get a distinct equivalence class of 1-cocycles $[\sigma_\mu]$ from $SL_2 \rightarrow V$, where
\begin{align*}
\sigma_\mu\left(\left(\begin{matrix} a & b \\ c & d \end{matrix}\right)\right) &=
\left(\begin{matrix}  \mu(cd)^{2^{r-1}}  \\ \mu\left(ab \right)^{2^{r-1}} \\ \mu^2\left( bc \right)^{2^r} \end{matrix}\right).
\end{align*}

But as before if we consider the action of $Z(L_\beta)$ on our 1-cocycles
\begin{align*}
(\mathbf{s}\cdot \sigma_\mu)\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &=
(2\alpha + \beta)^\vee(s) \cdot \sigma_\mu\left(\left(\begin{matrix} a & b \\ c & d \end{matrix}\right)\right)\\
&=
\left(\begin{matrix}  (s\mu)(cd)^{2^{r-1}}  \\ (s\mu)\left(ab \right)^{2^{r-1}} \\ (s\mu)^2\left( bc \right)^{2^r} \end{matrix}\right).
\end{align*}
our infinitely many $V$-conjugacy classes collapse to just two $P_\beta$-conjugacy classes:
\begin{align*}
\left[\sigma_0\right] &= \left\{ \sigma_0 \right\}, \\
\left[\sigma_1\right] &= \left\{ \sigma_\mu \, | \, \mu \in k^* \right\}.
\end{align*}

	\section{$G = G_2$}
	\label{g2}

	Let $G=G_2$. Fix a maximal torus, labeling the positive simple roots $\Delta=\{\alpha, \beta\}$ with $\beta$ being the long root. 

	\subsection{$V = R_u(P_\alpha)$}
	\label{g2:alpha}
	Let $V_\alpha = R_u(P_\alpha) = \langle U_\beta, U_{\alpha+\beta}, U_{2\alpha+\beta}, U_{3\alpha+\beta}, U_{3\alpha+2\beta}\rangle$.
	We write $v \in V_\alpha$ as a column vector,
	\begin{align*}
	\left(\begin{matrix}
			v_1\\
			v_2\\
			v_3\\
			v_4\\
			v_5
			\end{matrix}\right) &=
\epsilon_{\beta}(v_1)
\epsilon_{\alpha+\beta}(v_2)
\epsilon_{2\alpha+\beta}(v_3)
\epsilon_{3\alpha+\beta}(v_4)
	\epsilon_{3\alpha+2\beta}(v_5),
	\end{align*}
	so that we can clearly present the group law for $V_\alpha$, derived from the commutation relations in \cite[\S 33.5]{humphreys1975linear}.
	\begin{align*}
	\left(\begin{matrix}
			u_1\\
			u_2\\
			u_3\\
			u_4\\
			u_5
			\end{matrix}\right)\times
	\left(\begin{matrix}
			v_1\\
			v_2\\
			v_3\\
			v_4\\
			v_5
			\end{matrix}\right)
	&= \left(\begin{matrix}
			u_1 + v_1\\
			u_2 + v_2\\
			u_3 + v_3\\
			u_4 + v_4\\
			u_5 + v_5 + 3u_3v_2 - u_4v_1\\
			\end{matrix}\right).
	\end{align*}
	Let $\sigma$ be in $Z^1(SL_2, V_\alpha)_{\rho_r}$ such that $\sigma\left(\begin{matrix}t & 0\\0 & t^{-1}\end{matrix}\right) = 1$.
	By Proposition \ref{claim1}
	\begin{align*}
	\sigma\left(\begin{matrix} 1 & u \\ 0 & 1 \end{matrix}\right) =
\epsilon_{2\alpha+\beta}(x_3(u))
\epsilon_{3\alpha+\beta}(x_4(u))
	\end{align*}
	where the $x_3, x_4$ satisfy
	\begin{align}
	x_3(t^2u) &= t^{p^r}x_3(u)\label{eqn:g2x3}\\
							 x_4(t^2b) &= t^{3p^r}x_4(u)\label{eqn:g2x4},
	\end{align}
	for all $t\in k^*, u\in k$.

	Furthermore, since
	\begin{align*}
\sigma\left(\begin{matrix} 1 & u_1 + u_2 \\ 0 & 1\end{matrix}\right)
&= \left(\sigma\left(\begin{matrix} 1 & u_1 \\ 0 & 1\end{matrix}\right)\right)
	\left(\begin{matrix} 1 & u_1 \\ 0 & 1\end{matrix}\right) \cdot
	\sigma
	\left(\begin{matrix} 1 & u_2 \\ 0 & 1\end{matrix}\right),
	\end{align*}
	we get
	\begin{align*}
&\epsilon_{2\alpha+\beta}\left(x_3(u_1+u_2)\right)\epsilon_{3\alpha+\beta}\left(x_4(u_1+u_2)\right)
\\ &\quad	= \epsilon_{2\alpha+\beta}\left(x_3(u_1)\right)\epsilon_{3\alpha+\beta}\left(x_4(u_1)\right)
\epsilon_\alpha(u_1^{p^r})
\epsilon_{2\alpha+\beta}\left(x_3(u_2)\right)\epsilon_{3\alpha+\beta}\left(x_4(u_2)\right)
\epsilon_\alpha(-u_1^{p^r})
\\ &\quad	= \epsilon_{2\alpha+\beta}\left(x_3(u_1)\right)\epsilon_{3\alpha+\beta}\left(x_4(u_1)\right)
\epsilon_\alpha(u_1^{p^r})
\epsilon_{2\alpha+\beta}\left(x_3(u_2)\right)
\epsilon_\alpha(-u_1^{p^r})
\epsilon_{3\alpha+\beta}\left(x_4(u_2)\right)
\\ &\quad	= \epsilon_{2\alpha+\beta}\left(x_3(u_1)\right)\epsilon_{3\alpha+\beta}\left(x_4(u_1)\right)
\epsilon_{2\alpha+\beta}\left(x_3(u_2)\right)
\epsilon_{3\alpha+\beta}\left(x_4(u_2) -3u_1^{p^r}x_3(u_2)\right)
	\\ &\quad	= 
\epsilon_{2\alpha+\beta}\left(x_3(u_1) + x_3(u_2)\right)
\epsilon_{3\alpha+\beta}\left(x_4(u_1) + x_4(u_2) - 3u_1^{p^r}x_3(u_2)\right)
	\end{align*}
	We see that $x_3$ is an additive polynomial, so it is of the form
	\begin{align*}
	x_3(\lambda)&= \sum_{i=0}^m \mu_i \lambda^{p^i}\quad(\textrm{\cite[\S 20.3, Lemma A]{humphreys1975linear}}),
	\end{align*}
	for some $\mu_i\in k, m\in \mathbb{N}$, and $x_4$ satisfies
	\begin{align}\label{eqn:g2x42}
	x_4(\lambda_1 + \lambda_2) = x_4(\lambda_1) + x_4(\lambda_2) -3\lambda_2^{p^r}x_3(\lambda_2).
	\end{align}
	Suppose $x_3\neq 0$, so there exists $j\geq 0$ such that $\mu_j\neq 0$. Then by Equation \ref{eqn:g2x3}
	\begin{align*}
	&\mu_j (t^2u)^{p^j} = t^{p^r}\mu_j u^{p^j}\\
		&\Rightarrow t^{2p^j} = t^{p^r}\\
		&\Rightarrow p = 2, j = r-1.
		\end{align*}
		But then $x_3 = 0$, for
		\begin{align*}
		x_4(0) &= x_4(\lambda + \lambda) \\
							&= x_4(\lambda)+x_4(\lambda)-3\lambda^{2^r}x_3(\lambda)\quad(\textrm{Equation \ref{eqn:g2x42}}) \\
							&= 3\lambda^{2^r}x_3(\lambda),
		\end{align*}
		which implies that $x_3$ is constant, hence zero, as $\sigma\left(\begin{matrix}* & 0\\0 & *\end{matrix}\right) = 1$.

		Therefore $x_3 = 0$ in any case, and so by Equation \ref{eqn:g2x42}, $x_4$ is an additive polynomial. Then it is of the form
		\begin{align*}
		x_4(\lambda) = \sum_{i=0}^n \nu_i \lambda^{p^r},
		\end{align*}
		for some $\nu_i \in k, n\in\mathbb{N}$.
		If $x_4\neq 0$ then some $\nu_j\neq 0$, and we get
		\begin{align*}
		&\nu_j(t^2u)^{p^j} = t^{3p^r}\nu_j u^{p^j}\quad(\textrm{Equation \ref{eqn:g2x4}})\\
			&\Rightarrow t^{2p^j} = t^{3p^r}\\
			&\Rightarrow 2p^j = 3p^r,
		\end{align*}
		which implies that 2 divides $p$ and 3 divides $p$, a contradiction. Hence $x_4=0$ and
		\begin{align*}
		\sigma\left(\begin{matrix}* & *\\0 & *\end{matrix}\right) &= \sigma\left(\begin{matrix}1 & *\\0 & 1\end{matrix}\right) \quad(\textrm{Proposition \ref{imb:imu}}) \\
			&= 1.
			\end{align*}
			Therefore $H^1(SL_2(k), V_\alpha)_{\rho_r}$ is trivial by Lemma \ref{sl2_b_inj}. Note also that Lemma \ref{lem:second} is trivially satisfied.

			%\subsection{$V = R_u(P_\beta)$}
			%\label{g2:beta}
			%TODO Calculation goes here if I have time.

			\section{$G = C_3$}
			\label{c3}
			Let $G=C_3$. Fix a maximal torus, labeling the positive simple roots $\Delta=\{\alpha, \beta, \gamma\}$ with $\gamma$ being the long root and connected to $\beta$. 

			\subsection{$V = R_u(P_\alpha)$}
			\label{c3:alpha}

			Let $V_\alpha = R_u(P_\alpha) = \langle U_\beta, U_\gamma, U_{\alpha+\beta}, U_{\beta+\gamma}, U_{\alpha+\beta+\gamma}, U_{2\beta+\gamma}, U_{\alpha+2\beta+\gamma}, U_{2\alpha+2\beta+\gamma}\rangle$.
			We will write $v$ in $V_\alpha$ as a column vector,
			\begin{align*}
			\left(\begin{matrix}
					v_1\\
					v_2\\
					v_3\\
					v_4\\
					v_5\\
					v_6\\
					v_7\\
					v_8
					\end{matrix}\right)
=\epsilon_{\beta}(v_1)
\epsilon_{\gamma}(v_2)
\epsilon_{\alpha+\beta}(v_3)
\epsilon_{\beta+\gamma}(v_4)
\epsilon_{\alpha+\beta+\gamma}(v_5)
\epsilon_{2\beta+\gamma}(v_6)
\epsilon_{\alpha+2\beta+\gamma}(v_7)
	\epsilon_{2\alpha+2\beta+\gamma}(v_8),
	\end{align*}
	so that we can write the group law for $V_\alpha$ (\cite[\S 33.3, \S 33.4]{humphreys1975linear}) as
	\begin{align*}
	\left(\begin{matrix}
			u_1\\
			u_2\\
			u_3\\
			u_4\\
			u_5\\
			u_6\\
			u_7\\
			u_8
			\end{matrix}\right)
	\times
	\left(\begin{matrix}
			v_1\\
			v_2\\
			v_3\\
			v_4\\
			v_5\\
			v_6\\
			v_7\\
			v_8
			\end{matrix}\right)
	&=
	\left(\begin{matrix}
			u_1 + v_1\\
			u_2 + v_2\\
			u_3 + v_3\\
			u_4 + v_4 + u_2 + v_1\\
			u_5 + v_5 - u_3v_2\\
			u_6 + v_6 + u_2v_1^2 + 2u_4v_1\\
			u_7 + v_7 + u_2u_3v_1 + u_2v_1v_3 + u_5v_1 + u_4v_3\\
			u_8 + v_8 - u_3^2v_2 - 2u_3v_2v_3 + 2u_5v_3
			\end{matrix}\right).
	\end{align*}
	Let $\sigma$ be in $Z^1(SL_2, V_\alpha)$ such that $\sigma\left(\begin{matrix}* & 0\\0 & *\end{matrix}\right)$. By Proposition \ref{claim1}
	\begin{align*}
	\sigma\left(\begin{matrix}1 & u\\0 & 1\end{matrix}\right) = 
\epsilon_{\alpha+\beta}\left(x_3(u)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u)\right)
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u)\right)
	\end{align*}
	where $x_3, x_5, x_8$ satisfy
	\begin{align}
	x_3(t^2u) &= t^{p^r}x_3(u)\label{c3x3} \\
	x_5(t^2u) &= t^{p^r}x_5(u)\label{c3x5} \\
	x_8(t^2u) &= t^{2p^r}x_8(u),\label{c3x8}
	\end{align}
	Since $\alpha + \delta \notin \Phi$ for $\delta \in \{\alpha + \beta, \alpha + \beta + \gamma, 2\alpha + 2\beta + \gamma\}$, $\sigma\left(\begin{matrix}1 & u\\0 & 1\end{matrix}\right)$ is unchanged under the action of $\left(\begin{matrix}1 & *\\0 & 1\end{matrix}\right)$ for any $u\in k$. Then
\begin{align*}
	\sigma\left(\begin{matrix} 1 & u_1 + u_2 \\0 & 1\end{matrix}\right) &= 
	\left(\sigma\left(\begin{matrix} 1 & u_1\\0 & 1\end{matrix}\right)\right)
	\left(\left(\begin{matrix} 1 & u_1\\0 & 1\end{matrix}\right)\cdot
	\sigma\left(\begin{matrix} 1 & u_2\\0 & 1\end{matrix}\right)\right) \\ &=
	\sigma\left(\begin{matrix} 1 & u_1\\0 & 1\end{matrix}\right)
	\sigma\left(\begin{matrix} 1 & u_2 \\0 & 1\end{matrix}\right).
\end{align*}
Therefore
\begin{align*}
&\epsilon_{\alpha+\beta}\left(x_3(u_1 + u_2)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_1 + u_2)\right)
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_1 + u_2)\right) \\
&=
\epsilon_{\alpha+\beta}\left(x_3(u_1)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_1)\right)
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_1)\right)
\epsilon_{\alpha+\beta}\left(x_3(u_2)\right) \\
&\qquad\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_2)\right) 
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_2)\right) \\
&=
\epsilon_{\alpha+\beta}\left(x_3(u_1)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_1)\right)
\epsilon_{\alpha+\beta}\left(x_3(u_2)\right)
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_1)\right) \\
&\qquad\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_2)\right) 
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_2)\right) \\
&=
\epsilon_{\alpha+\beta}\left(x_3(u_1)\right)
\epsilon_{\alpha+\beta}\left(x_3(u_2)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_1)\right)
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_1) + 2x_3(u_2)x_5(u_1)\right) \\
&\qquad\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_2)\right) 
\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_2)\right) \\
&=
\epsilon_{\alpha+\beta}\left(x_3(u_1) + x_3(u_2)\right)
\epsilon_{\alpha+\beta+\gamma}\left(x_5(u_1) + x_5(u_2)\right) \\
&\qquad\epsilon_{2\alpha+2\beta+\gamma}\left(x_8(u_1) + x_8(u_2) + 2x_3(u_2)x_5(u_1)\right)
\end{align*}

We see that $x_3, x_5$ are additive polynomials, so by \cite[\S 20.3, Lemma A]{humphreys1975linear} they are of the form
\begin{align*}
	x_3(\lambda) &= \sum_{i=0}^m \mu_i\lambda^{p^r} \\
	x_5(\lambda) &= \sum_{i=0}^n \nu_i\lambda^{p^r},
\end{align*}
for some $\mu_i, \nu_i \in k, m,n \in \mathbb{N}$, while $x_8$ is of the form
\begin{align}\label{c3x8}
	x_8(\lambda_1 + \lambda_2) = x_8(\lambda_1) + x_8(\lambda_2) + 2x_3(\lambda_2)x_5(\lambda_1).
\end{align}

Suppose $x_3 \neq 0$. Then there exists $j \geq 0$ such that $\mu_j \neq 0$, so by Equation \ref{c3x3}
\begin{align*}
	&\mu_j(t^2u)^{p^j} = t^{p^r}\mu_ju^{p^j} \\
	&\Rightarrow t^{2p^j} = t^{p^r} \\
	&\Rightarrow 2p^j = p^r.
\end{align*}

Therefore $p = 2$, $j=r-1$ and $x_3(\lambda) = \mu \lambda^{2^{r-1}}$ for all $\lambda\in k$, for some fixed $\mu\in k$. The same argument shows that if $x_5 \neq 0$ then $p=2$ and $x_5(\lambda) = \nu \lambda^{2^{r-1}}$ for all $\lambda \in k$, for some fixed $\nu\in k$.

Consider Equation \ref{c3x8}. If $x_3$ or $x_4$ is nonzero then $p=2$, so $2x_3(\lambda_2)x_5(\lambda_1) = 0$. Conversely $2x_3(\lambda_2)x_5(\lambda_1) = 0$ if either of $x_3$ or $x_5$ is zero. Hence in either case $x_8$ is an additive polynomial, so by \cite[\S 20.3, Lemma A]{humphreys1975linear} $x_8$ is of the form
\begin{align*}
	x_8(\lambda_1 + \lambda_2) = x_8(\lambda_1) + x_8(\lambda_2).
\end{align*}
Moreover, in either case $\sigma\left(\begin{matrix}1 & *\\0 & 1\end{matrix}\right)$ lies in an abelian subgroup of $V_\alpha$. Hence Lemma \ref{lem:second} applies. The two cases are
\begin{align*}
p=2: \qquad&x_3(\lambda) = \mu \lambda^{2^{r-1}} \\
	&x_5(\lambda) = \nu \lambda^{2^{r-1}} \\
	&x_8(\lambda) = \omega \lambda^{2^r}, \\
p>2: \qquad&x_3=x_5=0 \\
	&x_8(\lambda) = \omega \lambda^{p^r}.
\end{align*}

The point of this Example calculation was to show that we could eventually apply Lemma \ref{lem:second} even though Proposition \ref{uabelian} does not apply, so we could not use Lemma \ref{lem:first}. This provides some evidence for Conjucture \ref{bigclaim}.

%\subsection{$V = R_u(P_\beta)$}
%\label{c3:beta}
%Calculation goes here

%\subsection{$V = R_u(P_\gamma)$}
%\label{c3:gamma}
%Calculation goes here

\section{$G = B_4$}
\label{b4}

Let $G = B_4$. Let $\mathrm{char}(k)=2$ and set $V:=\langle U_\phi\, |\, \phi \in \Phi^+, \phi \neq \gamma + \delta,\phi \neq \gamma+2\delta\} \rangle$. We will write
$
\mathbf{v} = \epsilon_\alpha(v_1) \epsilon_\beta(v_2) \epsilon_{\alpha+\beta}(v_3) \epsilon_{\beta+\gamma}(v_4) \epsilon_{\alpha+\beta+\gamma}(v_5) \epsilon_{\beta+\gamma+\delta}(v_6) \epsilon_{\alpha+\beta+\gamma+\delta}(v_7) \epsilon_{\beta+\gamma+2\delta}(v_8) \epsilon_{\alpha+\beta+\gamma+2\delta}(v_9) \\
\epsilon_{\beta+2\gamma+2\delta}(v_{10}) \epsilon_{\alpha+\beta+2\gamma+2\delta}(v_{11}) \epsilon_{\alpha+2\beta+2\gamma+2\delta}(v_{12}) \in V
$
as a column vector:
\begin{align*}
\mathbf{v} = \left( \begin{matrix}
	         v_1 \\
	         v_2 \\
	         v_3 \\
	         v_4 \\
	         v_5 \\
	         v_6 \\
	         v_7 \\
	         v_8 \\
	         v_9 \\
	         v_{10} \\
	         v_{11} \\
	         v_{12} 
	      \end{matrix}\right). 
\end{align*}
The Group Law on $V$ is
\begin{align*}
	     \mathbf{u}*
	     \mathbf{v}&=
	     \mathbf{u} + \mathbf{v} +
	     \left( \begin{matrix}
	         0 \\
	         0 \\
	         u_2v_1\\
	         0 \\
	         u_4v_1 \\
	         0 \\
	         u_6v_1\\
	         0 \\
	         u_8v_1\\
	         0 \\
	         u_{10}v_1\\
	         u_{10}v_1v_2 + u_8v_1v_4 + u_6^2v_1 + u_{11}v_2 + u_{10}v_3 + u_9v_4 + u_8v_5
	         	\end{matrix}\right).
\end{align*}

For integers $r,s\geq 0$ we have a homomorphism $\rho_{r,s}:SL_2\rightarrow \widetilde{A}_1\widetilde{A}_1 < L_{\{\gamma,\delta\}}$ defined by
\begin{align*}
\rho_{r,s}   \left(\begin{matrix} % or pmatrix or bmatrix or Bmatrix or ...
      1 & u \\
      0 & 1 \\
   \end{matrix}\right) &= \epsilon_\delta(u^{2^r})\cdot\epsilon_{\gamma+\delta}(u^{2^s}) \\
\rho_{r,s}   \left(\begin{matrix} % or pmatrix or bmatrix or Bmatrix or ...
      t & 0 \\
      0 & t^{-1} \\
   \end{matrix}\right) &= \delta^\vee(t^{2^r})\cdot(\gamma+\delta)^\vee(t^{2^s}) \\
\rho_{r,s}   \left(\begin{matrix} % or pmatrix or bmatrix or Bmatrix or ...
      0 & 1 \\
      1 & 0 \\
   \end{matrix}\right) &= n_\delta\cdot n_{\gamma+\delta} 
\end{align*}
from which we obtain an action of $SL_2$ on $V$:
\begin{align*}
\left( \begin{matrix}
	      a & b \\
	      c & d \\
	   \end{matrix}\right) \cdot \mathbf{v} &=
	   \left( \begin{matrix}
	   v_1 \\
	   c^{2^{s+1}} v_{10} + d^{2^{s+1}}v_2 \\
	   c^{2^{s+1}} v_{11} + d^{2^{s+1}}v_3 \\
	   c^{2^{r+1}} v_{8} + d^{2^{r+1}}v_4 \\
	   c^{2^{r+1}} v_{9} + d^{2^{r+1}}v_5 \\
	   v_6 + (bd)^{2^r}v_4 + (bd)^{2^s}v_2 + (ac)^{2^r}v_8 + (ac)^{2^s}v_{10} \\
	   v_7 + (bd)^{2^r}v_5 + (bd)^{2^s}v_3 + (ac)^{2^r}v_9 + (ac)^{2^s}v_{11} \\
	   a^{2^{r+1}}v_8 + b^{2^{r+1}}v_4 \\
	   a^{2^{r+1}}v_9 + b^{2^{r+1}}v_5 \\
	   a^{2^{s+1}}v_{10} + b^{2^{s+1}}v_2 \\
	   a^{2^{s+1}}v_{11} + b^{2^{s+1}}v_3 \\
	   v_{12} + (bd)^{2^{r+1}}v_4v_5 + (bd)^{2^{s+1}}v_2v_3 + (bc)^{2^{r+1}}(v_4v_9 + v_5v_8)\\ +\, (bc)^{2^{s+1}}(v_2v_{11} + v_3v_{10}) + (ac)^{2^{r+1}}(v_8v_9) + (ac)^{2^{s+1}}(v_{10}v_{11})
	   \end{matrix} \right)
\end{align*}

Now let $\sigma$ be a 1-cocycle from $SL_2$ to $V$ such that for all $t$ in $k^*$
\begin{align*}
\sigma\left(\begin{matrix} % or pmatrix or bmatrix or Bmatrix or ...
      t & 0 \\
      0 & t^{-1} \\
   \end{matrix}\right) = \left( \begin{matrix} 0 \\ \vdots \\ 0 \end{matrix}\right).
\end{align*}
Since $\sigma$ is a morphism of varieties, each component of $\sigma\left(\begin{matrix} 1 & u \\ 0 & 1\end{matrix}\right)$ should be a polynomial function of $u$, so we let
\begin{align*}
\sigma \left( \begin{matrix} % or pmatrix or bmatrix or Bmatrix or ...
      1 & u \\
      0 & 1 \\
   \end{matrix}\right) = \left( \begin{matrix} p_1(u) \\ \vdots \\ p_{12}(u) \end{matrix} \right),
\end{align*}
where each $p_i$ ($1\leq i \leq 12$) is as required. Applying $\sigma$ to the identity
\begin{align*}
  \left( \begin{matrix}
      t & 0 \\
      0 & t^{-1} \\
   \end{matrix}\right)
   \left(\begin{matrix}
      1 & u \\
      0 & 1 \\
   \end{matrix}\right)
   \left(\begin{matrix}
      t^{-1} & 0 \\
      0 & t \\
   \end{matrix}\right) &=
\left(   \begin{matrix}
      1 & t^2u \\
      0 & 1 \\
   \end{matrix}\right),
 \end{align*}
 gives rise to the following equations
 \begin{align}
 \label{tAct}
 p_i(t^2u) &= \left\{    \begin{array}{ll}
       p_i(u), & i = 1,6,7,12 \\
       t^{-2^{r+1}}p_i(u), & i = 4,5 \\
       t^{-2^{s+1}}p_i(u), & i = 2,3 \\
       t^{2^{r+1}}p_i(u), & i = 8,9 \\
       t^{2^{s+1}}p_i(u), & i = 10,11 \\
    \end{array}
 \right.
 \end{align}
It is clear that for $i = 1,6,7,12$ the polynomials $p_i$ must be constant-valued, say $\lambda_i$ for some fixed $\lambda_i$ in $k$ (resp). Furthermore, since $p_i(t^2u)$ involves only non-negative powers of $t$, $p_i$ must be the zero polynomial for $i=2,3,4,5$. Now consider the identity
\begin{align*}
  \left( \begin{matrix}
      1 & u_1 \\
      0 & 1 \\
   \end{matrix}\right)
   \left(\begin{matrix}
      1 & u_2 \\
      0 & 1 \\
   \end{matrix}\right) &=
    \left(\begin{matrix}
      1 & u_1 + u_2 \\
      0 & 1 \\
   \end{matrix}\right).
\end{align*}
Applying $\sigma$ to both sides yields
\begin{align*}
p_1(u_1 + u_2) &= p_1(u_1) + p_1(u_2) \\
p_6(u_1 + u_2) &= p_6(u_1) + p_6(u_2) \\
p_7(u_1 + u_2) &= p_7(u_1) + p_7(u_2) + p_6(u_1)p_1(u_2)\\
p_8(u_1 + u_2) &= p_8(u_1) + p_8(u_2) \\
p_9(u_1 + u_2) &= p_9(u_1) + p_9(u_2) + p_8(u_1)p_1(u_2)\\
p_{10}(u_1 + u_2) &= p_{10}(u_1) + p_{10}(u_2)\\
p_{11}(u_1 + u_2) &= p_{11}(u_1) + p_{11}(u_2) + p_{10}(u_1)p_1(u_2)\\
p_{12}(u_1 + u_2) &= p_{12}(u_1) + p_{12}(u_2) + \left(p_6(u_1)\right)^2p_1(u_2).
\end{align*}
Now we see that the constant polynomials $p_1,p_6,p_7,p_{12}$ must in fact be the zero polynomial and the remaining polynomials must be homomorphisms from $k\rightarrow k$. That is for some $w_j, x_j, y_j, z_j$ in $k$ and all $u$ in $k$
\begin{align*}
p_8(u) &= \sum_{j=0}^N w_j u^{2^j} \\
p_9(u) &= \sum_{j=0}^N x_j u^{2^j} \\
p_{10}(u) &= \sum_{j=0}^N y_j u^{2^j} \\
p_{11}(u) &= \sum_{j=0}^N z_j u^{2^j}, 
\end{align*}
If $\sigma$ is not the trivial 1-cocycle then one of the polynomials above is not the zero polynomial. Suppose for instance that $p_8$ is not the zero polynomial, so that $w_l\neq 0$ for some index $l\geq 0$. By (\ref{tAct})
\begin{align*}
\sum_{j=0}^N w_j (t^2u)^{2^j} &= t^{2^{r+1}}\sum_{j=0}^N w_j u^{2^j} \\
\Rightarrow\quad w_l (t^2u)^{2^l} &= t^{2^{r+1}} w_l u^{2^l} \\
\Rightarrow\quad l &= r.
\end{align*}
The same kind of calculation for the other polynomials shows that
\begin{align*}
p_8(u) = wu^{2^{r}}, \quad p_9(u) = xu^{2^{r}}, \\
p_{10}(u) = yu^{2^{s}}, \quad p_{11}(u) = zu^{2^{s}},
\end{align*}
for some $w,x,y,z$ in $k$.

So, we have
\begin{align*}
\sigma\left(\begin{matrix} a & b \\ 0 & a^{-1} \end{matrix}\right) &=
\sigma\left(\begin{matrix} a & 0 \\ 0 & a^{-1} \end{matrix}\right) * 
\left(\begin{matrix} a & 0 \\ 0 & a^{-1} \end{matrix}\right)\cdot
\sigma\left(\begin{matrix} 1 & a^{-1}b \\ 0 & 1 \end{matrix}\right) \\
&=
\left( \begin{matrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
w(ab)^{2^{r+1}} \\
x(ab)^{2^{r+1}} \\
y(ab)^{2^{s+1}} \\
z(ab)^{2^{s+1}} \\
0
\end{matrix} \right).
\end{align*}

We apply the same argument using the fact that each component of $\sigma\left(\begin{matrix} 1 & 0 \\ u & 1\end{matrix}\right)$ is a polynomial function, say $p'_i(u)$ for all $u$ in $k$, to get
\begin{align*}
\sigma\left(\begin{matrix} d^{-1} & 0 \\ c & d \end{matrix}\right) &=
\left( \begin{matrix}
0 \\
y'(cd)^{2^s} \\
z'(cd)^{2^s} \\
w'(cd)^{2^r} \\
x'(cd)^{2^r} \\
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0
\end{matrix} \right),
\end{align*}
for some $w', x', y', z'$ in $k$.

From this we deduce that
\begin{align*}
\sigma\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) &=
\sigma\left(
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\right) \\
&=
\sigma
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
*
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\cdot
\sigma\left(
\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\right) \\
&=
\sigma
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
*
\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\cdot
\left(
\sigma\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)
*
\left(\begin{matrix} 1 & 0 \\ 1 & 1 \end{matrix}\right)
\cdot
\sigma\left(\begin{matrix} 1 & 1 \\ 0 & 1 \end{matrix}\right)
\right) \\
&=
\left(\begin{matrix}
0 \\
y + y' \\
z + z' \\
w + w' \\
x + x' \\
w' + y' \\
x' + z' \\
w + w' \\
x + x' \\
y + y' \\
z + z' \\
w'x' + y'z'
\end{matrix}\right).
\end{align*}

Furthermore, since $\sigma\left(\begin{matrix} 0 & 1 \\ 1 & 0\end{matrix}\right)$ is fixed under the action of $\left(\begin{matrix} t & 0 \\ 0 & t^{-1}\end{matrix}\right)$, we have
\begin{align*}
\sigma\left(\begin{matrix} 0 & 1 \\ 1 & 0\end{matrix}\right) &=
\left(\begin{matrix}
n_1 \\
0 \\
0 \\
0 \\
0 \\
n_6 \\
n_7 \\
0 \\
0 \\
0 \\
0 \\
n_{12}
\end{matrix}\right),
\end{align*} 
for some $n_1, n_6, n_7, n_{12}$ in $k$. So in fact
\begin{align*}
w' &= w \\
x' &= x \\
y' &= y \\
z' &= z \\
n_1 &= 0\\
n_6 &=w+y\\
n_7 &= x+z\\
n_{12} &= wx + yz.
\end{align*}

Consider
$\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right)$.
If $c=0$ then we already have
\begin{align*}
\sigma\left(\begin{matrix} a & b \\ 0 & a^{-1} \end{matrix}\right) &=
\sigma\left(\begin{matrix} a & 0 \\ 0 & a^{-1} \end{matrix}\right) * 
\left(\begin{matrix} a & 0 \\ 0 & a^{-1} \end{matrix}\right)\cdot
\sigma\left(\begin{matrix} 1 & a^{-1}b \\ 0 & 1 \end{matrix}\right) \\
&=
\left( \begin{matrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
w(ab)^{2^{r+1}} \\
x(ab)^{2^{r+1}} \\
y(ab)^{2^{s+1}} \\
z(ab)^{2^{s+1}} \\
0
\end{matrix} \right).
\end{align*}
Otherwise, $c\neq 0$ and we can write
\begin{align*}
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &= 
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right),
\end{align*}
and so
\begin{align*}
\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &= 
\sigma\left(
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right)
\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
\right) \\
&=
\sigma \left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) *
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\sigma \left( 
\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right)
\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
\right) \\
&=
\sigma \left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) *
\left(\begin{matrix} 1 & ac^{-1} \\ 0 & 1 \end{matrix}\right) \cdot
\left( 
\sigma \left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) *
\left(\begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix}\right) \cdot
\sigma\left(\begin{matrix} c & d \\ 0 & c^{-1} \end{matrix}\right)
\right) \\
&=
\left(\begin{matrix}
0 \\
y(cd)^{2^s} \\
z(cd)^{2^s} \\
w(cd)^{2^r} \\
x(cd)^{2^r} \\
n_6 + w(ad)^{2^r} + y(ad)^{2^s} \\
n_7 + x(ad)^{2^r} + z(ad)^{2^s} \\
w(ab)^{2^r} \\
x(ab)^{2^r}  \\
y(ab)^{2^s} \\
z(ab)^{2^r} \\
n_{12} +wx(ad)^{2^{r+1}} + yz(ad)^{2^{s+1}}
\end{matrix}\right) \\
&=
\left(\begin{matrix}
0 \\
y(cd)^{2^s} \\
z(cd)^{2^s} \\
w(cd)^{2^r} \\
x(cd)^{2^r} \\
w(bc)^{2^r} + y(bc)^{2^s} \\
x(bc)^{2^r} + z(bc)^{2^s} \\
w(ab)^{2^r} \\
x(ab)^{2^r}  \\
y(ab)^{2^s} \\
z(ab)^{2^r} \\
wx(bc)^{2^{r+1}} + yz(bc)^{2^{s+1}}
\end{matrix}\right).
\end{align*}
We see that in any case
\begin{align*}
\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix} \right) &= 
\left(\begin{matrix}
0 \\
y(cd)^{2^s} \\
z(cd)^{2^s} \\
w(cd)^{2^r} \\
x(cd)^{2^r} \\
w(bc)^{2^r} + y(bc)^{2^s} \\
x(bc)^{2^r} + z(bc)^{2^s} \\
w(ab)^{2^r} \\
x(ab)^{2^r}  \\
y(ab)^{2^s} \\
z(ab)^{2^r} \\
wx(bc)^{2^{r+1}} + yz(bc)^{2^{s+1}}
\end{matrix}\right).
\end{align*}

Again, it can be shown that this is a sufficient condition for a 1-cocycle by applying \cite[Proposition 2]{martin2004nonab}.

Next we shall describe $H^1(SL_2, V)$. Recall that a 1-cocycle $\tau'$ is in the same 1-cohomology class as $\sigma$ if there is a $\mathbf{v}$ in $V$ such that
\begin{align*}
\tau'(g) &= \mathbf{v}*\sigma(g)*g.\mathbf{v}^{-1}
\end{align*}
for all $g$ in $SL_2$. Furthermore, $\tau'$ is conjugate to some 1-cocycle $\tau$, where $\tau$ has the added property that
\begin{align*}
\tau\left(\begin{matrix}t & 0 \\ 0 & t^{-1}\end{matrix}\right) &= \left(\begin{matrix} 0 \\ \vdots \\ 0\end{matrix}\right).
\end{align*}
Thus $\sigma$ is conjugate to $\tau$ by some $\mathbf{v}$ in $V$ that is fixed under the action of $\left(\begin{matrix}t & 0 \\ 0 & t^{-1}\end{matrix}\right)$:
\begin{align*}
\tau\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &=
\mathbf{v}*\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) *
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) \cdot \mathbf{v}^{-1}\\
&=
\left(\begin{matrix} 
v_1  \\
0 \\
0 \\
0 \\
0 \\
v_6 \\
v_7 \\
0 \\
0 \\
0 \\
0 \\
v_{12}
\end{matrix}\right)
*\sigma\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) *
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) \cdot 
\left(\begin{matrix} 
v_1  \\
0 \\
0 \\
0 \\
0 \\
v_6 \\
v_7 + v_1v_6 \\
0 \\
0 \\
0 \\
0 \\
v_{12} + v_1v_6^2
\end{matrix}\right)\\
&=
\left(\begin{matrix}
0 \\
y(cd)^{2^s} \\
(z+yv_1)(cd)^{2^s} \\
w(cd)^{2^r} \\
(x+wv_1)(cd)^{2^r} \\
w(bc)^{2^r} + y(bc)^{2^s} \\
(x+wv_1)(bc)^{2^r} + (z+yv_1)(bc)^{2^s} \\
w(ab)^{2^r} \\
(x+wv_1)(ab)^{2^r}  \\
y(ab)^{2^s} \\
(z+yv_1)(ab)^{2^r} \\
w(x+wv_1)(bc)^{2^{r+1}} + y(z+yv_1)(bc)^{2^{s+1}}
\end{matrix}\right)
\end{align*}
We can denote this relationship by
\begin{align*}
(w,x,y,z) &\sim (w, x+\lambda w, y, z + \lambda y),
\end{align*}
where the 4-tuple $(w,x,y,z)$ represents the 1-cocycle 
\begin{align*}
\left(\begin{matrix} a & b \\ c & d \end{matrix}\right) &\mapsto
\left(\begin{matrix}
0 \\
y(cd)^{2^s} \\
z(cd)^{2^s} \\
w(cd)^{2^r} \\
x(cd)^{2^r} \\
w(bc)^{2^r} + y(bc)^{2^s} \\
x(bc)^{2^r} + z(bc)^{2^s} \\
w(ab)^{2^r} \\
x(ab)^{2^r}  \\
y(ab)^{2^s} \\
z(ab)^{2^r} \\
wx(bc)^{2^{r+1}} + yz(bc)^{2^{s+1}}
\end{matrix}\right).
\end{align*}

We find infinitely many conjugacy classes, for instance for each $x, z$ in $k$ the family of classes of the form
\begin{align*}
[(0,x,0,z)] = \left\{(0,x,0,z)\right\}.
\end{align*}

Now we consider $P$-conjugacy. An element $\mathbf{s} = \alpha^\vee(s)(\beta + \gamma + \delta)^\vee(t)\in Z(L)$ acts on the 1-cocycle $\sigma$ by
\begin{align*}
(\mathbf{s}\cdot\sigma)\left(\begin{matrix} a & b \\ c & d\end{matrix}\right)
&=
\left(\begin{matrix}
0 \\
s^{-1}t^{2}y(cd)^{2^s} \\
sz(cd)^{2^s} \\
s^{-1}t^{2}w(cd)^{2^r} \\
sx(cd)^{2^r} \\
s^{-1}t^{2}(w(bc)^{2^r} + y(bc)^{2^s}) \\
sx(bc)^{2^r} + z(bc)^{2^s} \\
s^{-1}t^{2}w(ab)^{2^r} \\
sx(ab)^{2^r}  \\
s^{-1}t^{2}y(ab)^{2^s} \\
sz(ab)^{2^r} \\
t^2(wx(bc)^{2^{r+1}} + yz(bc)^{2^{s+1}})
\end{matrix}\right)
\end{align*}

It remains to show that there are infinitely many $P$-conjugacy classes by applying Lemma \ref{lem:p_h1}.

